{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Managing Missing Data\n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "Having looked at the data in chapter 1, we can see that some variables of interest such as Age are sometimes missing from the ~20% of the dataset. Our exploration also hinted that this information could be a valuable predictor for whether someone survived and so we might be heavily incentivised to use that feature. \n",
    "\n",
    "In this chapter, we'll answer three questions that are central to any data analysis:\n",
    "1. What's missing?\n",
    "2. Why's it missing?\n",
    "3. How are we going to handle missing data?\n",
    "\n",
    "Several methods for dealing with missing data, either using simple summary statistics or by devising more complex models for predicting missing values based on other features that are available. We'll also cover some statistical models that can handle missing data for you, and what benefits that might offer.\n",
    "\n",
    "Need for multivariate imputation to preserve associations between missing variables\n",
    "\n",
    "To map out the missing data, we will first consider the data in it's original form (i.e. before we did some simple feature engineering in Chapter 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data = 891 passengers\n",
      "Test data = 418 passengers\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = Path.cwd().parent.parent / 'data/titanic/original'        \n",
    "train = pd.read_csv(data_dir / 'train.csv')\n",
    "test = pd.read_csv(data_dir / 'test.csv')\n",
    "\n",
    "print(f\"Training data = {train.shape[0]} passengers\")\n",
    "print(f\"Test data = {test.shape[0]} passengers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. What's missing?\n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "In their book <i>Statistical Analysis with Missing Data</i> (3rd Edition, 2020), Little and Rubin distinguish between the patterns of missing data and the mechanisms of missing data. This distinction highlights that it's important to understand where and when data is missing, but also the reasons why data is absent. \n",
    "</span>\n",
    "\n",
    "### 2.1.1. Which columns have missing data\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "For a simple dataset like the titanic files, where each column is supposed to be a distinct measurement, we can start by simply asking which columns have missing data in each dataset. The <span style=\"color: #ffff00\">describe</span> method offers an easy way to do this.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived  Pclass Name Sex    Age  SibSp  Parch Ticket  \\\n",
       "train          0.0       0.0     0.0    0   0  177.0    0.0    0.0      0   \n",
       "test           0.0       NaN     0.0    0   0   86.0    0.0    0.0      0   \n",
       "\n",
       "       Fare Cabin Embarked  \n",
       "train   0.0   687        2  \n",
       "test    1.0   327        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1: Use the describe method of the dataframe\n",
    "#   - include='all'     includes both categorical and continuous data\n",
    "#   - .head(1)          gives us just the counts of non-missing data\n",
    "train.describe(include='all').head(1)\n",
    "\n",
    "# To get the number of missing values instead of valid values, use:\n",
    "train.shape[0] - train.describe(include='all').head(1)\n",
    "\n",
    "# We could take this further and contrast counts of missing values for train and test data\n",
    "pd.concat([\n",
    "    train.shape[0] - train.describe(include='all').head(1).rename({'count':'train'}),    \n",
    "    test.shape[0] - test.describe(include='all').head(1).rename({'count':'test'})\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>\n",
    "We have missing rows for <i>Age</i> and <i>Cabin</i> in both test and train data, but we also have rare cases where the port of embarcation (<i>Embarked</i>) is missing from the training data and the <i>Fare</i> paid by one passenger is missing form the test dataset. One can also view the missing Surivival values in the test set as missing data, and thus <span style=\"color:#ff0000\">the project goal of predicting survival can be viewed as an imputation problem</span>.\n",
    "<p>\n",
    "<img src=\"missing_data.png\" alt=\"Tabular data shown as rectangles with missing sections indicating missing data\" width=\"500\">\n",
    "</p>\n",
    "<br></br>\n",
    "Leaving aside this perspective for the moment,  we can see how the pattern of missing data shapes our approach to model design. Either we ignore Age and Cabin, or we develop a strategy to deal with missing values. If we had reason to believe that the test data would have no missing values, we could also simply remove those passengers with missing ages or cabins from the dataset and train our model on data from passengers without missing data. This is sometimes called a 'complete case' analysis.\n",
    "\n",
    "### 2.1.2. Complete case analysis: Why impute rather than delete?\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>\n",
    "In complete case analysis, we drop any rows or columns that contain missing data. This method is simple and easy to implement, but has three major drawbacks:   \n",
    "<br>    (1) Dropping cases is inefficient and expensive, both from a modelling perspective where reduced sample size limit our insights, and from a practical perspective where data points may be expensive to collect. \n",
    "<br>(2) Dropping missing data may bias the results if the missing data is not missing completely at random.\n",
    "<br>(3) Dropping cases with missing data doesn't provide a useful strategy for making predictions on new test data that contains missing values. If we just delete missing data, then either we can't base predictions a feature that contains missing data (which is highly undesirable) or we have to skip test cases where data is missing (which will hurt performance badly).\n",
    "</p><p>\n",
    "In the titanic dataset, we have so many cases of missing cabin data that to drop passengers with missing data would reduces the size of our training set dramatically. We also have good reason to believe that features like Age and Deck (a transform from Cabin) are associated with survival (see Chapter 1) and so we definitely want to include them in the model. For the reasons above, we will avoid removing missing data. \n",
    "</p>\n",
    "\n",
    "\n",
    "### 2.1.3. What denotes a missing value - NaN vs. Numbers?\n",
    "<p>\n",
    "In the code above using the <b>describe</b> function, we're assuming that missing values are coded as NaNs, but that might not always be the case. Sometimes  data acqusition systems will return values out of range or zeros. Numeric coding can be a major issue when those responsible for the data collection use zeros or other values, as it distorts the data's statistics while simultaneously masking missing data. It's therefore always worth looking out impossible numbers or inflated counts at specific numbers.  \n",
    "</p><p>\n",
    "In the titanic dataset, we have already identified the zero fares as one example of this probelm (Chapter 1.2.4). We also noted that within several string variables (e.g. Name and Ticket) we can extract information for some passengers, but that is missing for others. In these cases, missing information may be encoded as an empty string ('') rather than nans.\n",
    "</p>\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Why is data missing?\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>\n",
    "Data may be missing for a specific reason, sometimes called the \"missingness mechanism\". For example if Age and Cabin data was collected from survivors. Those that perished would not have been available to provide the information. We call such data missing not at random (MNAR) and it can be substantially  <b>biased</b>. \n",
    "</p><p>\n",
    "If data is MNAR, then the fact that a datapoint is missing can be informative. Below we explore why data is missing from the titanic dataset and consider how that might help us predict survival. To help us, we're going to bring back some of the features we extracted in Chapter 1:\n",
    "</p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked' 'age_measure' 'age_group' 'log_fare'\n",
      " 'people_on_ticket' 'ticket_num' 'ticket_prefix' 'no_ticket_prefix'\n",
      " 'n_rooms' 'Deck' 'Surname' 'Title' 'professional_title' 'nob_title'\n",
      " 'family_size']\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path.cwd().parent.parent / 'data/titanic/chapter_1'        \n",
    "\n",
    "train = pd.read_csv(data_dir / 'train_Ch01.csv')\n",
    "test = pd.read_csv(data_dir / 'test_Ch01.csv')\n",
    "\n",
    "print(train.columns.to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Zero Fares: Passengers as Employees\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "Why would someone pay nothing for a ticket on the most luxurious ship in the world? The obvious first answer is the people who sail the ship, but sailors are not part of the passenger list. Maybe there's something in the data that can shed light on who these passengers might be:\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>n_rooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>39.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>112050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Campbell, Mr. William</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>239853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Chisholm, Mr. Roderick Robert Crispin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>112051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>239853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>239854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Fry, Mr. Richard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>112058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>112059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Ismay, Mr. Joseph Bruce</td>\n",
       "      <td>49.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>112058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>49.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>LINE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Johnson, Mr. William Cahoone Jr</td>\n",
       "      <td>19.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>LINE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Knight, Mr. Robert J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>239855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Leonard, Mr. Lionel</td>\n",
       "      <td>36.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>LINE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Parkes, Mr. Francis \"Frank\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>239853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Parr, Mr. William Henry Marsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>112052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Reuchlin, Jonkheer. John George</td>\n",
       "      <td>38.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>19972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>60.5</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>3701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>LINE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>Watson, Mr. Ennis Hastings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>239856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name   Age   Sex  Pclass  Ticket  \\\n",
       "837                 Andrews, Mr. Thomas Jr  39.0  male       1  112050   \n",
       "388                  Campbell, Mr. William   NaN  male       2  239853   \n",
       "266  Chisholm, Mr. Roderick Robert Crispin   0.0  male       1  112051   \n",
       "387         Cunningham, Mr. Alfred Fleming   NaN  male       2  239853   \n",
       "592       Frost, Mr. Anthony Wood \"Archie\"   NaN  male       2  239854   \n",
       "843                       Fry, Mr. Richard   NaN  male       1  112058   \n",
       "366                  Harrison, Mr. William  40.0  male       1  112059   \n",
       "372                Ismay, Mr. Joseph Bruce  49.0  male       1  112058   \n",
       "269                    Johnson, Mr. Alfred  49.0  male       3    LINE   \n",
       "268        Johnson, Mr. William Cahoone Jr  19.0  male       3    LINE   \n",
       "786                   Knight, Mr. Robert J   NaN  male       2  239855   \n",
       "266                    Leonard, Mr. Lionel  36.0  male       3    LINE   \n",
       "386            Parkes, Mr. Francis \"Frank\"   NaN  male       2  239853   \n",
       "715          Parr, Mr. William Henry Marsh   NaN  male       1  112052   \n",
       "849        Reuchlin, Jonkheer. John George  38.0  male       1   19972   \n",
       "152                     Storey, Mr. Thomas  60.5  male       3    3701   \n",
       "267           Tornquist, Mr. William Henry  25.0  male       3    LINE   \n",
       "743             Watson, Mr. Ennis Hastings   NaN  male       2  239856   \n",
       "\n",
       "     n_rooms  \n",
       "837        1  \n",
       "388        1  \n",
       "266        1  \n",
       "387        1  \n",
       "592        1  \n",
       "843        1  \n",
       "366        1  \n",
       "372        3  \n",
       "269        1  \n",
       "268        1  \n",
       "786        1  \n",
       "266        1  \n",
       "386        1  \n",
       "715        1  \n",
       "849        1  \n",
       "152        1  \n",
       "267        1  \n",
       "743        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    pd.concat([\n",
    "        train[train['Fare'] == 0.0],\n",
    "        train[train['Fare'].isna()],\n",
    "        test[test['Fare'] == 0.0],           # test data indicated by Survived=NaN\n",
    "        test[test['Fare'].isna()]\n",
    "    ])\n",
    "    .sort_values(by='Name')\n",
    "    .filter(['Name','Age','Sex','Pclass','Ticket','n_rooms'])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>If you have background knowledge about the titanic disater, or you've watched the James Cameron film, then some of those names might pop out at you. In particular, <b>Mr Joseph Ismay</b> - a man who paid nothing but had three cabins - what's going on there? Well, he was the managing director of White Star Lines, the company that owned the ship. It's therefore not surprising that he didn't pay to travel, or that he got several rooms. Also listed is <b>Mr Thomas Andrews</b>, the chief designer of the ship and one of the \"<b>Titanic Guarentee Group</b>\" - a team of 10 engineers sent by the shipbuilders Harland & Wolff to accompany the maiden voyage. Of the 10 in the group, 9 are listed above, while the 10th (Joseph Thompson) disembarked at Southamptom and is not in the dataset.\n",
    "</p><p>\n",
    "What about others - could they also be employees? Every individual identified was a man, and given that few women were in the workforce in 1912, it makes it more viable that all these individuals had some relevant profession. Indeed, external research confirms that several men identified above (William Tornquist, William Cahoone Johnson Jr., Alfred Johnson, and Lionel Leonard) were being transported by their employer (<b>American Line</b>). It therefore seems reasonable to summerise that people on zero fares represent a specialty group.\n",
    "</p><p>\n",
    "The zero values used to mark these passengers may distort the relationship between Fare and Surival, or other variables by reducing the average fare of those who did not survive. We should therefore mask these zero values with nans so that we can then impute appropriate missing values in Section 2.3.\n",
    "</p><p>\n",
    "<i>Note that we are thus introducing more missing values than we had before, but now the fare data makes more sense.</i>\n",
    "</p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Fare'] = train['Fare'].mask(train['Fare'] == 0)\n",
    "test['Fare'] = test['Fare'].mask(test['Fare'] == 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "\n",
    "Passengers who paid nothing had a very low survival rate (1/15) in the training data. This suggest that anyone in the category was very likely to go down with the ship. A column indicating the special status of zero fare passengers is thus likely to be useful in predicting surival in the test set.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['zero_fare'] = train['Fare'].isna()\n",
    "test['zero_fare'] = test['Fare'].isna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Who is Mrs Stone? The case of missing embarcation\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "In the training data, there are two cases of missing embracation information. There is no embarcation data missing in the test data. Who are these passengers and is there any reason their point of embarcation is unknown?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>zero_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  zero_fare  \n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN      False  \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN      False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Embarked.isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two women appear to be travelling on the same ticket staying in the same first class cabin, with no direct relatives in either case. Is anyone else travelling on that ticket, or staying in that Cabin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>zero_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  zero_fare  \n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN      False  \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN      False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_no = \"113572\"\n",
    "cabin_no = \"B28\"\n",
    "\n",
    "train[(train['Ticket'].str.match(ticket_no)) | (train['Cabin'].str.match(cabin_no))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "No, doesn't look like it. This is where outside research can help... Looking up the Amelie Icard, we discover that she was a maid for Mrs Stone and that both embarked at Southampton. We will add this data specifically to these records here:\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].fillna('S', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Missing Age Data\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>We noted in Chapter 1.2.1. that age data might be missing because passengers did not surivive. While it is true that the average survival rate is substantially lower in cases where age is missing, there are still 30% of passengers who survive but have no age data. Could these be, for example, children who have lost a parent and don't know their age?\n",
    "</p><p>\n",
    "Let's find out by testing a hypothesis: If children are more likely to be missing Age data, then we might expect there to be more passengers with the title 'Master' missing Age data in the survivors than in those passengers lost. (Note here that I'm using the 'Master' title rather than 'Miss' due to the potential confound of unmaried women that results from naming conventions of the time). To test this hypothesis, we can run a simple Chi-squared test:\n",
    "</p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_missing'] = train['Age'].isna()\n",
    "test['age_missing'] = test['Age'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PassengerId    \n",
      "                  count    \n",
      "Survived              0   1\n",
      "age_missing                \n",
      "False                15  21\n",
      "True                  2   2\n",
      "Chi-squared test that observations deviate from expectations: 1 d.f. Chi-squared = 0.0, p = 1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chisq_data = (\n",
    "    train\n",
    "    .query(\"Title == ' Master'\")            # Noted Bug: White space in titles\n",
    "    .groupby(['age_missing','Survived'])\n",
    "    .agg({'PassengerId':['count']})\n",
    "    .reset_index()\n",
    "    .pivot(columns='Survived', index='age_missing')\n",
    ")\n",
    "\n",
    "print(chisq_data)\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(chisq_data.values) \n",
    "print(f\"Chi-squared test that observations deviate from expectations: {dof} d.f. Chi-squared = {chi2}, p = {p}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "Doesn't look like this group is any more likely to be missing data when surviving. (The same is true if we look at Miss)\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Cabins\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>The largest amount of missing data comes from the Cabin column, where there are fewer datapoints than there are NaN values. Why is this data absent when presumably everyone had a room? \n",
    "</p><p>\n",
    "In Chapter 1, we discussed how the organization of the ship tells us something about how Cabins were assigned, with first class passengers in Sections A-E, second class passengers in D through F and third class in sections E to G. There are also differences in Fare between sections and at least some instances where Cabin information is available for other passengers travelling on the same ticket. All these pieces of information may help us impute the Section of the ship in which passengers were staying, even if we can't recover the actual room. \n",
    "</p><p>\n",
    "If we look at the outcomes for those with Cabin information present, they are fare more likely to survive. This suggests a sampling bias in which cabin information was recovered predominatly from surivors. It's important to note that this bias isn't a hard rule, as there were some people for whom Cabin data is available and didn't survive, and vice versa.\n",
    "</p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train\n",
    "    .assign(cabin_missing = lambda x: x['Cabin'].isna())\n",
    "    .groupby('cabin_missing')\n",
    "    .agg({'Survived':['count', 'sum', 'mean'],})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\n",
    "    (train['Cabin'].isna()) &\n",
    "    (train['Survived'] == 1)\n",
    "].head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Testing if data is missing at random\n",
    "\n",
    "## 2.4. Preparing the data ahead of imputation\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "The fact that data is missing may be interesting itself, and even indicative of the target variable (e.g. if ages of people who died couldn't be recovered). This is particularly the case for features with lots of missing data, such as Age and Class, and so for each of these features, we add a column noting whether the feature is missing or not:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_missing'] = train['Age'].isna()\n",
    "test['age_missing'] = test['Age'].isna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>Looking ahead to methods of imputation, some approaches such as Regression Imputation, may only take in numeric data. If we want to predict missing data based on categorical information (e.g. predicting Age from Class), we must create numerical values representing each value of the category (e.g. Male=0, Female=1 etc.).\n",
    "</p>\n",
    "<p>Note that in the code below, I've used the map method with a specified dictionary of values to make the coding of variables explicit and the numeric values easier to interpret. Mapping in this way also ensures consistency between parallel operations on test and train datasets, while also ensuring that any future values of the source feature that aren't in the map do not receive values. \n",
    "</p>\n",
    "<p>This latter point can be important if we don't know the distribution of feature categories in the test dataset - e.g. if males and females were in the training data, but only females were in the test data and we used a method such as <i>factorize</i>, females would encoded as 1 in the training data, and 0 in the test data. That could be a major bug! (Not that I've ever done that...)\n",
    "<p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map = {'male':0,'female':1}\n",
    "train['gender_numeric'] = train['Sex'].map(gender_map)\n",
    "test['gender_numeric'] = test['Sex'].map(gender_map)\n",
    "\n",
    "embark_map = {'C':1,'Q':2,'S':3}\n",
    "train['embarked_numeric'] = train['Embarked'].map(embark_map)\n",
    "test['embarked_numeric'] = test['Embarked'].map(embark_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.drop(train.index[train[\"age_missing\"]])\n",
    "# test = test.drop(test.index[test[\"age_missing\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.5. Single Imputation Methods: \n",
    "\n",
    "\n",
    "\n",
    "### 2.5.1. Mean, median or mode\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    " This involves replacing the missing data with the mean or median value of the non-missing data in the same column. This can be useful if the missing data is missing at random and if the data is normally distributed.\n",
    "<br></br>\n",
    " As shown in Chapter 1, most of the input features for the titanic dataset are not normally distributed and so mean imputation is unsuitable for an in-depth analysis. \n",
    " </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with mean \n",
    "# train.fillna(train.mean(), inplace=True)\n",
    "# test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "# Replace with median \n",
    "# train.fillna(train.mean(), inplace=True)\n",
    "# test.fillna(test.mean(), inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<b>Disadvantages</b>\n",
    "\n",
    "Mean imputation leads to the sample variance of the filled-in data underestimating the true variance by a factor proportional to the percentage of missing data. Imputation also distorts the empirical (observed) distribution of the data, which is reflected in metrics such as percentiles. Mean imputation also leads to underestimates in covariance, which can affect our ability to use a variety of modelling approaches that involve covariance matrices (e.g. correlation).\n",
    " \n",
    "If the data is not normally distributed or if the missing data is not missing at random, these statistics can also potentially introduce bias. The same is true if there are group differences in means that are ignored during imputation, such as using the global mean Age when the average age of first class passengers is greater than third class passengers.\n",
    "</span>\n",
    "\n",
    "<span style=\"font-size:14px;font-family:Times New Roman;line-height:1.2;color:#aaaaaa\">\n",
    "Side note: Often people will use mean imputation just to get a solution working, for example in interviews or courses where time is limited. Beyond the biological situations in which most of statistics was developed, the assumption of normality in real-world scenarios rarely met (see Chapter 1.2.1 on Age distribution for an example)\n",
    "</span>\n",
    "\n",
    "### 2.5.2. Conditional Mean Imputation\n",
    "\n",
    "Divide data up into classes within which one can then take the mean and apply it to all missing observations in the same class. For example, group passengers by Gender and PClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3. Regression Imputation\n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>\n",
    "This involves using a regression model to predict the missing values based on the non-missing values in the same row or other relevant variables. This can be useful if the missing data is not missing at random and if there is a strong relationship between the missing and non-missing values. However, it can also introduce bias and error if the regression model is misspecified or if there is not a strong relationship between the variables.\n",
    "</p><p>\n",
    "In the case of the titanic dataset, we are somewhat limited in the predictors available for imputation. We can get an idea of the relationships between continuous variables by looking at the correlation matrix. Note that here we're considering the factorized version of categorical variables such as gender and class (and class has ordinal implications in that 1st is different from 2nd class in at least the same \"direction\" as 2nd is different from 3rd class)\n",
    "</p><p>\n",
    "If we try to impute values this way, we'll find that a simple regression model does a bad job and predicts impossible values, such as negative ages.\n",
    "</p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[['Age','SibSp','Fare','PassengerId','gender_numeric','Pclass','Parch']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that uses the model to make predictions for missing values\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Build model from available data\n",
    "# predictors = ['SibSp','Fare','gender_numeric','Pclass','Parch']\n",
    "\n",
    "# X = train[predictors].dropna().values\n",
    "# y = train[\"Age\"].dropna().values\n",
    "\n",
    "# model = LinearRegression().fit(X, y)\n",
    "\n",
    "# idx = train[train[\"age_missing\"]].index\n",
    "# train.loc[idx, \"Age\"] = model.predict(train.loc[idx, predictors]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to note that regression predictions are still draws from the center of a distribution and will thus continue to systematically underestimate variability. Moreover, \"single imputation cannot reflect sampling variability under one model for missingness or uncertainty about the correct model for missingness\" (Little and Rubin, 2020). This prevents us from assessing how sensitive subsequent analysis is to different theories about why data is missing. \n",
    "\n",
    "Buck's method \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. \"Hot Deck\" methods: Draws based on implicit models\n",
    "\n",
    "\n",
    "### 2.6.1. Stochastic Regression Imputation\n",
    "\n",
    "A random residual is added \n",
    "\n",
    "https://www.kaggle.com/code/shashankasubrahmanya/missing-data-imputation-using-regression/notebook\n",
    "\n",
    "### 2.6.2. Random sampling with replacement\n",
    "\n",
    "What if the mean, median or mode doesn't provide a good summary of the data? Instead we can randomly sample from the distribution of available values. The limitation of this approach is that each individual estimate is uncertain, although we can use multiple imputation to assess how much of an impact this uncertainty has on our model performance. We'll talk about this more in Section ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_by_resampling(df:pd.DataFrame, colname:str, n_impute:int=1) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "        Args:    \n",
    "            df: dataframe containing variable with missing data\n",
    "            colname: variable to fill missing data for\n",
    "            n_impute: number of rounds of imputation\n",
    "    \"\"\"\n",
    "\n",
    "    for impute_count in range(n_impute):\n",
    "\n",
    "        new_name = f\"{colname}_R{impute_count}\"\n",
    "        new_vals = (\n",
    "            df[colname]\n",
    "            .dropna()\n",
    "            .sample(\n",
    "                n=df[colname].isna().sum(),\n",
    "                replace=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        new_vals.index = df[df[colname].isna()].index\n",
    "\n",
    "        df[new_name] = pd.concat([df[colname].dropna(), new_vals])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = replace_by_resampling(train, colname='Age', n_impute=20)\n",
    "test = replace_by_resampling(test, colname='Age', n_impute=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>\n",
    "\"The advantage of the hot deck method is that, unlike mean imputation, the distribution of the sampled values of Y is not distorted by the imputations.\" (Little and Rubin, 2019). Sampling <i>with</i> replacement leads to additional sample variance, which can be reduced by sampling <i>without</i> replacement. \n",
    "</p></span>\n",
    "\n",
    "### 2.6.2. Hot-deck sampling with adjustment cells \n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "We might have good reason to believe that a variable with missing data is dependent on other features in the data. For example if female passengers tended to be older than male passengers. It may therefore be useful to resample data specifically from the most relevant data - i.e. if we have a missing age value for a male passenger, we resample from the available ages for only men. This organization of the dataset is sometimes called *stratification* and can be particularly useful in cases like gender, where there are a small number of possible categories\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def replace_by_stratafied_resampling(df:pd.DataFrame, colname:str, strata:List[str], n_impute:int=1) -> pd.DataFrame:\n",
    "\n",
    "    # Create the groupby object once to save time\n",
    "    group_obj = df[strata + [colname]].groupby(strata)\n",
    "\n",
    "    # For every round of imputation\n",
    "    for impute_count in range(n_impute):\n",
    "\n",
    "        # Create new column with original data, including missing data\n",
    "        new_name = f\"{colname}_S{impute_count}\"\n",
    "\n",
    "        # For each stratification layer\n",
    "        for strate_vals, strata_df in group_obj:\n",
    "\n",
    "            new_vals = (\n",
    "                strata_df[colname]\n",
    "                .dropna()\n",
    "                .sample(\n",
    "                    n = strata_df[colname].isna().sum(),\n",
    "                    replace=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "            new_vals.index = strata_df[strata_df[colname].isna()].index\n",
    "\n",
    "            df[new_name] = pd.concat([df[colname].dropna(), new_vals])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = replace_by_stratafied_resampling(train, colname='Age', strata = ['Sex','Pclass'], n_impute=20) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the effects of imputation by resampling with and without stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_resampled_distributions(df, cols, ax):\n",
    "\n",
    "    sns.ecdfplot(\n",
    "        data = (\n",
    "            df\n",
    "            .query('Age.isna()')\n",
    "            .filter(cols + ['PassengerId'])\n",
    "            .melt(id_vars=['PassengerId'], value_name='Imputed_Age', var_name='ImputeIdx')\n",
    "        ),\n",
    "        x = 'Imputed_Age',\n",
    "        hue = 'ImputeIdx',\n",
    "        ax = ax,\n",
    "        legend = False\n",
    "    )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2, **{'figsize':(8,3)})\n",
    "\n",
    "resamp_cols = [c for c in train.columns if 'Age_R' in c]\n",
    "plot_resampled_distributions(train, resamp_cols, axs[0])\n",
    "axs[0].set_title('without')\n",
    "\n",
    "strat_resamp_cols = [c for c in train.columns if 'Age_S' in c]\n",
    "plot_resampled_distributions(train, strat_resamp_cols, axs[1])\n",
    "axs[1].set_title('without stratification')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train\n",
    "    .query('Age.isna()')\n",
    "    .filter(resamp_cols + ['PassengerId'])\n",
    "    .melt(id_vars=['PassengerId'], value_name='Imputed_Age', var_name='ImputeIdx')\n",
    "    .groupby('ImputeIdx')\n",
    "    .agg({'Imputed_Age':['std']})\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train\n",
    "    .query('Age.isna()')\n",
    "    .filter(strat_resamp_cols + ['PassengerId'])\n",
    "    .melt(id_vars=['PassengerId'], value_name='Imputed_Age', var_name='ImputeIdx')\n",
    "    .groupby('ImputeIdx')\n",
    "    .agg({'Imputed_Age':['std']})\n",
    "    .mean()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation with weighting\n",
    "\n",
    "In the case of Deck, we know that there are a limited number of decks for a given class (e.g. decks E to G for third class passengers). This means that we can use something about class to infer the deck on which a passenger was. However, passengers may not be equally distributed across decks - for example if deck E and F were shared with second class passengers. If we want to make a guess about which deck a passenger was staying, it would therefore be wise to take into account the relative probabilities of staying on each deck based on class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.3. Hot Deck based on a matching metric\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "To impute missing Ages\n",
    "\n",
    "1. Define a space from fully-observed metrics (e.g. a 1D space defined by Fare)\n",
    "2. For each passenger with missing Age data:\n",
    "    <br>i) measure the distance in that space to all other passengers with known Ages\n",
    "    <br>ii) select passengers with known Ages within a specific distance (e.g. fares of ± £5)\n",
    "    <br>iii) randomly sample an Age from within this selected group for use as imputed value\n",
    "\n",
    "An advance on this is *predictive mean modelling* in which distances are based on predictions from a regression model\n",
    "\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. ML approaches\n",
    "### 2.7.1. K-Nearest Neighbors Imputation\n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "<p>\n",
    "This involves using the values of the k-nearest neighbors to the missing data point to impute the missing value. This can be useful if the data is missing at random and if the missing data is similar to the values of its neighboring points. However, it can also introduce bias and error if the data is not missing at random or if the nearest neighbors are not representative of the missing data point.\n",
    "</p><p>\n",
    "These are just a few examples of methods for replacing missing data. There are many other methods and techniques that can be used, and the appropriate method to use depends on the specific context and characteristics of the missing data. It is important to carefully evaluate the missing data and consider the potential implications of different methods before deciding on a course of action.\n",
    "</p></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 3)\n",
    "\n",
    "# Select columns to use for impute\n",
    "columns_for_impute = ['Pclass','SibSp', 'Parch', 'Fare', 'gender_numeric', 'embarked_numeric','Age']\n",
    "\n",
    "# Fit the imputer to the data\n",
    "imputer.fit(train[columns_for_impute])\n",
    "\n",
    "# Transform the data\n",
    "imputed_data = imputer.transform(train[columns_for_impute])\n",
    "\n",
    "# Create a new dataframe with the imputed data\n",
    "imputed_df = pd.DataFrame(imputed_data, columns = columns_for_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.5. Neural Networks\n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "Given the hype, it's important to remember that a neural net isn't magic - it can't find relationships if they don't exist. Also, if those relationships are very complex, we may not have enough data to find them.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Create a sample dataset with missing values\n",
    "data = np.array([[1, 2, np.nan],\n",
    "                 [3, 4, 5],\n",
    "                 [6, np.nan, 7],\n",
    "                 [np.nan, 8, 9]])\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(3,)),\n",
    "    keras.layers.Dense(10),\n",
    "    keras.layers.Dense(3)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(data, data, epochs=100)\n",
    "\n",
    "# Use the trained model to impute missing values\n",
    "imputed_data = model.predict(data)\n",
    "\n",
    "# Print the imputed dataset\n",
    "print(imputed_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Cold Deck methods\n",
    "\n",
    "Sampling from other datasets - e.g. census data, passenger information from other ships\n",
    "\n",
    "## 2.9. Further Considerations\n",
    "\n",
    "### 2.9.1. Documenting Missing Data\n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "We began this chapter by discussing how to find missing data and think about the reasons why some datapoints might be absent. While the titanic dataset is useful for illustrating the general flow of data science workflows, it should be noted that it's best practice to document the sources and reasons for missing data at the point of data collection. \n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "### 2.9.2. Approaches that are robust to missing data\n",
    "\n",
    "- Generalized linear mixed models\n",
    "- XGBoost (Sparsity Aware Split Finding)\n",
    "\n",
    "### 2.9.3. Preventing Data Leakage: Never merge the train and test data\n",
    "\n",
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "\n",
    "When imputing missing data, one might think that we should combine data from the training and test datasets, so that we can maximise our ability to estimate missing values. However, if we were to merge the two datasets, we would potentially risk **data leakage** that might undermine the model we're training. \n",
    "\n",
    "A simple example using regression imputation shows you why: Here we simulate a simple experiment in which age is correlated with ticket fare, but the correlation coefficients and ranges of fares in test and train data are different:\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_passengers, max_age = 200, 80\n",
    "\n",
    "train_age = np.random.rand(n_passengers) * max_age\n",
    "test_age = np.random.rand(n_passengers) * (max_age/2)              # test subjects are half as old \n",
    "\n",
    "train_fare = (train_age * 10) + (25*np.random.rand(n_passengers))   # y = a + bx + noise\n",
    "test_fare = (test_age * 5) + (25*np.random.rand(n_passengers))      \n",
    "\n",
    "# mask a subset of ages (data has no order)\n",
    "proportion_missing = 0.3\n",
    "train_age[:int(n_passengers*proportion_missing)] = np.nan   \n",
    "fares_for_missing_data = train_fare[:int(n_passengers*proportion_missing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute values using linear regression with only training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = train_fare[~np.isnan(train_age)].reshape(-1,1)\n",
    "y = train_age[~np.isnan(train_age)].reshape(-1,1)\n",
    "\n",
    "training_only = LinearRegression().fit(X, y)\n",
    "trained_only_prediction = training_only.predict(fares_for_missing_data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now impute values using linear regression on merged test and training data\n",
    "X_merged = np.vstack((X, test_fare.reshape(-1, 1)))\n",
    "y_merged = np.vstack((y, test_age.reshape(-1, 1)))\n",
    "\n",
    "merged_model = LinearRegression().fit(X_merged, y_merged)\n",
    "merged_prediction = merged_model.predict(fares_for_missing_data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14px;font-family: Arial;line-height:1.5\">\n",
    "When we plot the results in the cell below, we can see that the imputed ages of subjects is very strongly affected by the merging of train and test datasets. If we were then to build our survival model based on the ages imputed after merging, that model would also be influenced by the test data. In deployment, such a model may generalize poorly because it can no longer rely on the leaked information that allowed it to perform well on the test data.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(train_fare, train_age, marker='.', color='c', alpha=0.5, label='Train (Observed)')\n",
    "plt.scatter(test_fare, test_age, marker='.', color='orange', alpha=0.5, label='Test (Observed)')\n",
    "\n",
    "plt.scatter(\n",
    "    train_fare[np.isnan(train_age)], \n",
    "    trained_only_prediction, \n",
    "    marker='x', s=5, color='b', label='Train (Imputed)')\n",
    "\n",
    "plt.scatter(\n",
    "    train_fare[np.isnan(train_age)], \n",
    "    merged_prediction, \n",
    "    marker='x', s=5, color='r', label='Merged (Imputed)')\n",
    "\n",
    "plt.ylabel('Age (Years)')\n",
    "plt.xlabel('Fare (£)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.4.2. Multiple Imputation (MI)\n",
    "\n",
    "In the statistics community, it is common practice to perform multiple imputations, generating, for example, *m* separate imputations for a single feature matrix. Each of these *m* imputations is then put through the subsequent analysis pipeline (e.g. feature engineering, clustering, regression, classification). The *m* final analysis results (e.g. held-out validation errors) allow the data scientist to obtain understanding of how analytic results may differ as a consequence of the inherent uncertainty caused by the missing values. \n",
    "\n",
    "One advantage of MI is that it allows us to compare models of missingness and see how sensitive our analysis is to our theories about why data is missing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Final steps\n",
    "\n",
    "When identifying and imputing missing data, we modified some columns for which we've already done feature engineering. We must remember to then update these columns in order to pass on the improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Repeat the log transform from Chapter 1, but now zero values aren't a problem\n",
    "import numpy as np\n",
    "\n",
    "train['log_fare'] = np.log(train['Fare'])\n",
    "test['log_fare'] = np.log(test['Fare'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we're no longer missing any values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    train.shape[0] - train.describe(include='all').head(1).rename({'count':'train'}),    \n",
    "    test.shape[0] - test.describe(include='all').head(1).rename({'count':'test'})\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Python Packages\n",
    "\n",
    "Imputation in python is available through several libraries, however some of these are still in development:\n",
    "\n",
    "* [MIDASpy](https://github.com/MIDASverse/MIDASpy)\n",
    "* [sklearn.impute](https://scikit-learn.org/stable/modules/impute.html) \n",
    "* [impyute](https://impyute.readthedocs.io/en/master/)\n",
    "\n",
    "\n",
    "\n",
    "### R Packages\n",
    "\n",
    "The R ecosystem also has some well developed packages for imputation:\n",
    "* MICE (Multivariate Imputation via Chained Equations) \n",
    "* [rMIDAS](https://github.com/MIDASverse/rMIDAS)\n",
    "* Amelia\n",
    "* missForest\n",
    "* Hmisc\n",
    "* mi\n",
    "\n",
    "\n",
    "### Applications of Imputation beyond the Titanic\n",
    "\n",
    "Recommendation systems\n",
    "\n",
    "Imagine another universe in which the titanic didn't sink, and instead of survival values, we had ratings of how good the journey was. If we had those ratings for all the White Star line ships, then we could build a table of every passenger and every possible journey, with some data filled in for completed journeys and other data missing for possible trips in the future. Using imputation, we could fill in that missing data to predict passenger's ratings for those possible trips and then select those trips that are likely to be well rated. This is a **recommendation system** like those used in a variety of services (Netflix, Spotify etc.) and is based on the solution to an imputation problem of filling in missing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b730ead757b5d9b842526340519d98f65a574c00873e9637238694ddd8f9228"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
